{"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","gpuClass":"standard"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Set up de librerias y configuraci칩n","metadata":{"id":"T6x3iFywaHw8"}},{"cell_type":"code","source":"!pip install ml-collections","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A2CQ_eXDQUZE","outputId":"424af0c0-7848-4f03-8572-34f82a062eb7","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport cv2\nimport os\nimport random\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision\nfrom torch.optim.lr_scheduler import CyclicLR\nfrom torch.optim import Adam\nimport torch.nn.functional as F\n\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import StratifiedKFold\n\nfrom albumentations import Compose, Normalize, Resize\nfrom albumentations.pytorch import ToTensorV2\n\nimport ml_collections\nfrom tqdm import tqdm","metadata":{"id":"8-JDbiRiOLKv","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!wget https://challenges-asset-files.s3.us-east-2.amazonaws.com/data_sets/Data-Science/4+-+events/SchneiderElectricEuropeanHackathon22/train.csv\n!wget https://challenges-asset-files.s3.us-east-2.amazonaws.com/data_sets/Data-Science/4+-+events/SchneiderElectricEuropeanHackathon22/test.csv\n!wget https://challenges-asset-files.s3.us-east-2.amazonaws.com/data_sets/Data-Science/4+-+events/SchneiderElectricEuropeanHackathon22/train_test_data.zip\n!unzip train_test_data.zip > /dev/null","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"La20P4B6OPr8","outputId":"34ae5db6-2cf8-4003-91fa-7295105fc8a3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cfg = ml_collections.ConfigDict()\ncfg.base_path = Path(\"/kaggle/working\") # change to /content for Colab\ncfg.train_csv_path = cfg.base_path / \"train.csv\"\ncfg.test_csv_path = cfg.base_path / \"test.csv\"\ncfg.data_dir = cfg.base_path / \"train_test_data\"\ncfg.seed = 23\ncfg.batch_size = 16\ncfg.num_classes = 3\ncfg.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"id":"CTHVYew6QQ3c","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_torch(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True","metadata":{"id":"q6XXPD9IWnxF","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seed_torch(cfg.seed)","metadata":{"id":"rj9C5ZNxb2eK","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Analisis de datos exploratorio b치sico","metadata":{"id":"7teU-xxgaLU8"}},{"cell_type":"code","source":"label_to_text = {\n    0: \"Plantation\",\n    1: \"Grassland/Shrubland\",\n    2: \"Smallholder Agriculture\"\n}","metadata":{"id":"u-PzF9RJWLA5","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(cfg.train_csv_path)\ntest_df = pd.read_csv(cfg.test_csv_path)","metadata":{"id":"e2nLG9OHSN5j","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Como podemos ver, est치 desbalanceado:","metadata":{"id":"OB4HzgoraSVb"}},{"cell_type":"code","source":"train_df[\"label\"].value_counts()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KRpmq_q-aRAr","outputId":"cd3ecc82-e030-46d3-9e91-262d50feb890","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Datasets","metadata":{"id":"PtpWvRYzaP_4"}},{"cell_type":"markdown","source":"Validaci칩n cruzada (stratified)","metadata":{}},{"cell_type":"code","source":"folds = train_df.copy()\ntrain_labels = folds[\"label\"].values\n\nkf = StratifiedKFold(n_splits=5)\nfor fold, (train_index, val_index) in enumerate(kf.split(folds.values, train_labels)):\n    folds.loc[val_index, 'fold'] = int(fold)\n    \nfolds['fold'] = folds['fold'].astype(int)\nfolds.to_csv('folds.csv', index=None)","metadata":{"id":"gvKvAz_CdMzu","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"folds.head()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"zdfWyHvsdX5s","outputId":"1c834ebf-afb3-46fe-ca63-0eb863bc2ff0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ZeroDeforestationDataset(Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        img_path = self.df.loc[idx, \"example_path\"]\n        image = cv2.imread(img_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        label = self.df.loc[idx, \"label\"]\n\n        if self.transform:\n            augmented = self.transform(image=image)\n            image = augmented['image']\n\n\n        return image, label","metadata":{"id":"CsXoZ90yQtqM","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_transforms():\n    return Compose([\n            Normalize(\n                mean=[0.5, 0.5, 0.5],\n                std=[0.5, 0.5, 0.5],\n            ),\n            ToTensorV2(),\n        ])","metadata":{"id":"mDQmVXFBZMJs","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_on_fold(fold, model):\n    trn_idx = folds[folds['fold'] != fold].index\n    val_idx = folds[folds['fold'] == fold].index\n\n    training_data = ZeroDeforestationDataset(folds.loc[trn_idx].reset_index(drop=True), transform=get_transforms())\n    valid_data = ZeroDeforestationDataset(folds.loc[val_idx].reset_index(drop=True), transform=get_transforms())\n\n    train_dataloader = DataLoader(training_data, batch_size=cfg.batch_size, shuffle=True)\n    valid_dataloader = DataLoader(valid_data, batch_size=cfg.batch_size, shuffle=False)\n\n    epochs = 200\n    lr = 0.01\n    model.to(cfg.device)\n\n    best_score = 0.\n    best_loss = np.inf\n\n    optimizer = Adam(model.parameters(), lr=lr)\n    criterion = nn.CrossEntropyLoss()\n\n    for epoch in range(epochs):\n        model.train()\n        average_loss = 0.\n\n        for i, (images, labels) in tqdm(enumerate(train_dataloader)):\n            images = images.to(cfg.device)\n            labels = labels.to(cfg.device)\n\n            y_preds = model(images)\n            loss = criterion(y_preds, labels)\n\n            optimizer.step()\n            optimizer.zero_grad()\n\n            average_loss += loss.item() / len(train_dataloader)\n        \n        model.eval()\n        average_val_loss = 0.\n        preds = np.zeros((len(valid_data)))\n\n        for i, (images, labels) in tqdm(enumerate(valid_dataloader)):\n            images = images.to(cfg.device)\n            labels = labels.to(cfg.device)\n\n            with torch.no_grad():\n                y_preds = model(images)\n            \n            preds[i * cfg.batch_size: (i+1) * cfg.batch_size] = y_preds.argmax(1).to(\"cpu\").numpy()\n            loss = criterion(y_preds, labels)\n            average_val_loss += loss.item() / len(valid_dataloader)\n                \n        score = f1_score(folds.loc[val_idx][\"label\"].values, preds, average='macro')\n        print(f\"Epoch {epoch} | average train loss: {average_loss:.5f} | average val loss: {average_val_loss:.5f} | F1: {score:.5f}\")\n\n        if score > best_score:\n            best_score = score\n            print(f\"Saving new model with best score {best_score:.5f}\")\n            torch.save(model.state_dict(), f'fold{fold}_best_score.pth')\n        if average_val_loss < best_loss:\n            best_loss = average_val_loss\n            print(f\"Saving new model with best loss: {best_loss:.4f}\")\n            torch.save(model.state_dict(), f'fold{fold}_best_loss.pth')","metadata":{"id":"LcI_d84Fgasc","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seed_torch(cfg.seed)\nfor fold in range(2, 5):\n    model = torchvision.models.mobilenet_v3_small(pretrained=True) # Change\n    model.avgpool = nn.AdaptiveAvgPool2d(1)\n    model.classifier[-1] = nn.Linear(model.classifier[-1].in_features, 3)\n    train_on_fold(fold, model)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"IcRluD8Bl0P3","outputId":"59244a25-e69c-4002-c368-740b9cfd03bb","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"Nkj6Uyzfs4Vg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}